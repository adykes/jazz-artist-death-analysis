{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import itertools\n",
    "from time import sleep\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting out with just the list of jazz pianists, but this will be somehow expanded to get data from the lists of \n",
    "# drummers, bassists, saxophonists, trumpeters, floutists, bonists, COMPOSERS, etc. (?)\n",
    "result = requests.get(\"https://en.wikipedia.org/wiki/List_of_jazz_trombonists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(result.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'href'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-0e40348a0529>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;31m# I get an error here but it doesn't affect the outcome of my scraping because the error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;31m# occurs after the names and links have already been scraped.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0muTrombonistsLinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0martist_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0martist_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                 \u001b[1;31m#print(f'{artist_tag.text}, {artist_tag.attrs[\"href\"]}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'href'"
     ]
    }
   ],
   "source": [
    "# Gets the names and hrefs of all the people on the page by exploiting <a> tag and reads them into uBassistsLinks, \n",
    "# a dictionary\n",
    "uTrombonistsLinks = dict()\n",
    "\n",
    "# The page of the list of jazz bassists was a little more tricky to figure out... That's why this scraper is \n",
    "# much more convoluted than the pianist one, which it was based off of. One major issue was that there are \n",
    "# pictures \"within\" the lists so that some of the picture tags get read into the scraper. \n",
    "# I figure this could use some review, but for the time being I mostly only care about collecting the data. \n",
    "\n",
    "# Finding the first h2 tag in order to use the .next_siblings iterator that's part of the bs4 library\n",
    "body = soup.find('div', {'class' : 'mw-parser-output'})\n",
    "first_h2 = body.find('h2')\n",
    "for h2 in body.find_all('h2'):\n",
    "    if h2.find('span', {'class' : 'mw-headline'}):\n",
    "        first_h2 = h2\n",
    "        break\n",
    "\n",
    "for sib in first_h2.next_siblings:\n",
    "    if type(sib) == bs4.element.Tag:\n",
    "        for li in sib.find_all('li'):\n",
    "            for artist_tag in li.find_all('a'):\n",
    "                # I get an error here but it doesn't affect the outcome of my scraping because the error \n",
    "                # occurs after the names and links have already been scraped. \n",
    "                uTrombonistsLinks.update( {artist_tag.text : artist_tag.attrs[\"href\"] } )\n",
    "                #print(f'{artist_tag.text}, {artist_tag.attrs[\"href\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(uTrombonistsLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrombonistsLinks = dict(list(uTrombonistsLinks.items())[0:159])\n",
    "#print(newTrombonistsLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraper to get the year dates that come after most of the names. Similar structure to the link scraper. \n",
    "uTrombonistsYears = dict()\n",
    "\n",
    "body = soup.find('div', {'class' : 'mw-parser-output'})\n",
    "first_h2 = body.find('h2')\n",
    "for h2 in body.find_all('h2'):\n",
    "    if h2.find('span', {'class' : 'mw-headline'}):\n",
    "        first_h2 = h2\n",
    "        break\n",
    "\n",
    "for sib in first_h2.next_siblings:\n",
    "    if type(sib) == bs4.element.Tag:\n",
    "        for li in sib.find_all('li'):\n",
    "            s = li.text\n",
    "            #print(s)\n",
    "            \n",
    "            noParens = False\n",
    "            yearDates = ''\n",
    "            fullName = ''\n",
    "            \n",
    "            # Extracting the dates from s\n",
    "            # Using regular expression to extract everything within the parentheses and assign it to variable years\n",
    "            if re.search('\\(([^)]+)', s):\n",
    "                years = re.search('\\(([^)]+)', s).group(1)\n",
    "            # Testing if the format of the dates is \"born XXXX\" or \"XXXX-XXXX\" by simply determining if there \n",
    "            # is a whitespace in the string (I should think about making this process a little more robust)\n",
    "                if len(years.split()) > 1:\n",
    "                # Don't want the word \"born\" in the year data, so only taking the year using .split()\n",
    "                    yearDates = years.split()[1].strip()\n",
    "                else:\n",
    "                    yearDates = years.strip()\n",
    "            else:\n",
    "                yearDates = 'NaN'\n",
    "            # If there is no year data given, then there are no parentheses, which allows the scripts to \n",
    "            # properly extract the artist's name\n",
    "                noParens = True\n",
    "            \n",
    "            # Extracting the artist's name from s\n",
    "            # If there are parentheses, simply take a substring of s that ends at the first '('\n",
    "            if noParens == False:\n",
    "                name = s[0:s.find('(')]\n",
    "                fullName = name.strip()\n",
    "            # If there aren't any parentheses, then just take s as it is (stripped of whitespace of course)\n",
    "            else:\n",
    "                fullName = s.strip()\n",
    "            \n",
    "            #print(fullName, yearDates, '\\n')\n",
    "        \n",
    "            # Now append the name and year data to the uBassistsYears dictionary\n",
    "            uTrombonistsYears.update( {fullName : yearDates})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrombonistsYears = dict(list(uTrombonistsYears.items())[0:159])\n",
    "#print(newTrombonistsYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To combine the two dictionaries so that for each artist's name, there is a wiki and years listed\n",
    "combinedList = [newTrombonistsLinks, newTrombonistsYears]\n",
    "fullTrombonistsList = dict()\n",
    "\n",
    "for artist in newTrombonistsLinks.keys():\n",
    "    fullTrombonistsList[artist] = tuple(fullTrombonistsList[artist] for fullTrombonistsList in combinedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(fullTrombonistsList)\n",
    "\n",
    "#for key, value in fullTrombonistsList.items():\n",
    "#    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom dictionary with pyspellchecker that contains most, if not all, instruments used to play jazz\n",
    "spell = SpellChecker(language = None, case_sensitive = True)\n",
    "a = spell.word_frequency.load_words(['Piano', 'Vocals', 'Keyboards', 'Double bass', 'Upright bass', 'Electric bass', \n",
    "                                     'Saxophone', 'Clarinet', 'Trumpet', \n",
    "                                     'Trombone', 'Drums', 'Guitar', 'Flute', 'Vibraphone', 'Banjo', 'Violin', 'Viola', \n",
    "                                     'Cello', 'Synthesizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating DataFrame to store the information on the pianists\n",
    "pDF = pd.DataFrame(columns = ['artist', 'instrument', 'birthdate', 'deathdate', 'birth_year', 'death_year'])\n",
    "\n",
    "# Main script that will take the wikis in the fullPianistsList dictionary and scrape the data in the biographical\n",
    "# table for each artist. I have done much research into the legality and ethicality of this operation, and I've \n",
    "# determined that it's okay to run a script like this as long as I have at least a one-second delay inbetween \n",
    "# each iteration of the below for loop, so as to not create too much traffic. \n",
    "\n",
    "# pianist = pianist's name; linkYear = a tuple where the first element is the wiki link and the second element \n",
    "# is the string containing the artist's dates: ( /wiki/ARTIST_NAME, (XXXX OR XXXX-XXXX) )\n",
    "\n",
    "# For testing the DataFrame:\n",
    "runs = 0\n",
    "\n",
    "for bonist, linkYear in fullTrombonistsList.items():\n",
    "    \n",
    "    # For testing purposes\n",
    "    if runs < 30:\n",
    "        #print(bonist, linkYear[1])\n",
    "    \n",
    "        bday = ''\n",
    "        dday = ''\n",
    "        \n",
    "        bYear = ''\n",
    "        dYear = ''\n",
    "        \n",
    "        # instrumentList is important for a later operation, although it can most likely be simplified\n",
    "        instrumentList = []\n",
    "    \n",
    "        # Create the link by appending the wikipedia link for the artist onto the end of the general wikipedia link\n",
    "        wikiLink = 'https://en.wikipedia.org' + linkYear[0]\n",
    "    \n",
    "        # Following the basic requests and bs4 process to read in a webpage\n",
    "        pInfo = requests.get(wikiLink)\n",
    "        pSoup = bs4.BeautifulSoup(pInfo.text, \"html.parser\")\n",
    "    \n",
    "        # Finding the biographical information table, which is always in a table with the class = infobox vcard plainlist\n",
    "        # However, some pages don't have the table, which is why there is a conditional first. \n",
    "        if pSoup.find('table', {'class' : 'infobox vcard plainlist'}):\n",
    "            \n",
    "    \n",
    "            # aTable is the tag in which the script will find all of the necessary information\n",
    "            aTable = pSoup.find('table', {'class' : 'infobox vcard plainlist'})\n",
    "    \n",
    "            # All of the necessary information is within the <tr> row element \n",
    "            for table in aTable.find_all('tr'):\n",
    "    \n",
    "                # First, finding the primary instrument of the artist (which is all that this project will\n",
    "                # be concerned with for the moment, sorry multi-instrumentalists). The instrument data is listed in\n",
    "                # the <td> tag with the class = note. However, because the script must account for the fact that\n",
    "                # there are multi-instrumentalists, the script only returns the first instrument that is found. \n",
    "                # In lieu of a more efficient way to do this, there is an index that will only allow the instrumentList\n",
    "                # to append the first instrument it finds. This should probably be fixed too. \n",
    "                if table.find('td', {'class' : 'note'}):\n",
    "                    index = 0\n",
    "                    for string in table.find('td', {'class' : 'note'}).stripped_strings:\n",
    "                        if index == 0:\n",
    "                            string = string.split(',')[0]\n",
    "                            string = spell.correction(string)\n",
    "                            instrumentList.append(string.split(',')[0])\n",
    "                            index += 1\n",
    "        \n",
    "                # Finding the birthday of the artist. If there is one, it is always contained within the span class = \n",
    "                # bday tag, and the date can be accessed with the .string bs4 method\n",
    "                if table.find('span', {'class' : 'bday'}):\n",
    "                    #print(table.find('span', {'class' : 'bday'}).string)\n",
    "                    bday = table.find('span', {'class' : 'bday'}).string\n",
    "                    bYear = bday[0:4]\n",
    "        \n",
    "                # Finding the deathdate of the artist. If there is one, it is usually contained within the span style = \n",
    "                # display:none tag. However, there are multiple pieces of information that can be contained within a \n",
    "                # style = diplay:none tag. Fortunately, the death date is the only piece of information that is \n",
    "                # accessible via the .string method, so the script checks for the possibility of the .string method\n",
    "                # and then removes the parentheses which always surround it. \n",
    "                if table.find('span', {'style' : 'display:none'}):\n",
    "                    for row in table.find_all('span', {'style' : 'display:none'}):\n",
    "                        if row.string:\n",
    "                            #print(row.string[1:-1])\n",
    "                            dday = row.string[1:-1]\n",
    "                            dYear = dday[0:4]\n",
    "                    \n",
    "     \n",
    "            # Lines 85-102 and lines 113-129 use the year data from the \"List of jazz pianists\" page to fill in \n",
    "            # the DataFrame when information is not found in the individual artist's vtable\n",
    "            if not bday:\n",
    "                bday = linkYear[1][0:4]\n",
    "                bYear = bday\n",
    "                \n",
    "            if not dday:\n",
    "                if linkYear[1] == 'NaN':\n",
    "                    dday = 'NaN'\n",
    "                    dYear = 'NaN'\n",
    "                else:\n",
    "                    if len(linkYear[1]) > 4:\n",
    "                        dday = linkYear[1][5:9]\n",
    "                        dYear = dday\n",
    "                    else:\n",
    "                        dday = 'NaN' # Make these 'Present' if other solution doesn't work\n",
    "                        dYear = 'NaN'\n",
    "            \n",
    "            if not instrumentList:\n",
    "                instrumentList.append('Trombone')\n",
    "        \n",
    "            #print('\\n')\n",
    "        \n",
    "            # Time delay on for loop\n",
    "            #sleep(1.0)\n",
    "            \n",
    "            \n",
    "    \n",
    "        else:\n",
    "            #print('\\n')\n",
    "            if len(linkYear[1]) > 4:\n",
    "                bday = linkYear[1][0:4]\n",
    "                bYear = bday\n",
    "                dday = linkYear[1][5:9]\n",
    "                dYear = dday\n",
    "            else:\n",
    "                bday = linkYear[1]\n",
    "                bYear = bday\n",
    "                if bday == 'NaN':\n",
    "                    dday = 'NaN'\n",
    "                    dYear = 'NaN'\n",
    "                else:\n",
    "                    dday = 'NaN'  # Make these 'Present' if other solution doesn't work\n",
    "                    dYear = 'NaN'\n",
    "                    \n",
    "            if not instrumentList:\n",
    "                instrumentList.append('Trombone')\n",
    "                \n",
    "                \n",
    "        # Appending the values to the DataFrame        \n",
    "        pDF = pDF.append( {'artist' : bonist, 'instrument' : instrumentList[0], 'birthdate' : str(bday),\n",
    "                           'deathdate' : str(dday), 'birth_year' : bYear, 'death_year' : dYear}, ignore_index = True)\n",
    "    \n",
    "        runs += 1\n",
    "        #print(runs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# To make it easier to loop through DataFrame? \n",
    "# pDF.set_index('Artist', inplace = True)\n",
    "\n",
    "# Deleting Birth Year and Death Year columns for now because I don't think they're that necessary given the solution\n",
    "# I've decided to pursue. However, I will leave this like so for now because I don't want to commit to this solution \n",
    "# yet. \n",
    "pDF.drop(columns = ['birth_year', 'death_year'], inplace = True)\n",
    "\n",
    "#print(pDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'alive' column to the DataFrame using np.select() \n",
    "\n",
    "conditions = [ (pDF['birthdate'] == 'NaN') & (pDF['deathdate'] == 'NaN'), (pDF['deathdate'] == 'NaN'), \n",
    "             (pDF['deathdate'] != 'NaN') ]\n",
    "\n",
    "values = ['NaN', True, False]\n",
    "\n",
    "pDF['alive'] = np.select(conditions, values)\n",
    "#print(pDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forcing all of the dates into datetime objects \n",
    "\n",
    "pDF['bday_dt'] = pd.to_datetime(pDF['birthdate'], errors = 'coerce')\n",
    "pDF['dday_dt'] = pd.to_datetime(pDF['deathdate'], errors = 'coerce')\n",
    "\n",
    "# Account for the age of people who are alive today as well\n",
    "conditions = [ (pDF['alive'] == 'True'), (pDF['alive'] == 'False'), (pDF['alive'] == 'NaN') ]\n",
    "\n",
    "values = [ (pd.to_datetime('today') - pDF['bday_dt']).astype('timedelta64[Y]').astype(float),\n",
    "         (pDF['dday_dt'] - pDF['bday_dt']).astype('timedelta64[Y]').astype(float), 'NaN' ]\n",
    "\n",
    "pDF['age_yrs'] = np.select(conditions, values)\n",
    "\n",
    "#display(pDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs the .csv file that was then cleaned in Excel and put back into the jazz-pianist-files folder as \n",
    "# jazz_pianists_cleaned1.csv\n",
    "pDF.to_csv('jazz_trombonists1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
