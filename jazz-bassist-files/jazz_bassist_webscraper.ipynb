{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import itertools\n",
    "from time import sleep\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting out with just the list of jazz pianists, but this will be somehow expanded to get data from the lists of \n",
    "# drummers, bassists, saxophonists, trumpeters, floutists, bonists, COMPOSERS, etc. (?)\n",
    "result = requests.get(\"https://en.wikipedia.org/wiki/List_of_jazz_bassists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(result.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'href'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-d7350c98dfc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0martist_tag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mli\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;31m# I get an error here but it doesn't affect the outcome of my scraping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0muBassistsLinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0martist_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0martist_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;31m#print(f'{artist_tag.text}, {artist_tag.attrs[\"href\"]}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'href'"
     ]
    }
   ],
   "source": [
    "# Gets the names and hrefs of all the people on the page by exploiting <a> tag and reads them into uBassistsLinks, \n",
    "# a dictionary\n",
    "uBassistsLinks = dict()\n",
    "\n",
    "body = soup.find('div', {'class' : 'mw-parser-output'})\n",
    "first_h2 = body.find('h2')\n",
    "\n",
    "for sib in first_h2.next_siblings:\n",
    "    if type(sib) == bs4.element.Tag:\n",
    "        #print(sib)\n",
    "        for li in sib.find_all('li'):\n",
    "            #print(li)\n",
    "            for artist_tag in li.find_all('a'):\n",
    "                # I get an error here but it doesn't affect the outcome of my scraping\n",
    "                uBassistsLinks.update( {artist_tag.text : artist_tag.attrs[\"href\"] } )\n",
    "                #print(f'{artist_tag.text}, {artist_tag.attrs[\"href\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBassistsLinks1 = dict(list(uBassistsLinks.items())[0:144])\n",
    "newBassistsLinks2 = dict(list(uBassistsLinks.items())[145:249])\n",
    "newBassistsLinks3 = dict(list(uBassistsLinks.items())[262:432])\n",
    "newBassistsLinks4 = dict(list(uBassistsLinks.items())[437:464])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "fNewBassistsLinks = dict(chain.from_iterable(d.items() for d in (newBassistsLinks1, newBassistsLinks2, newBassistsLinks3, newBassistsLinks4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eGomez = False\n",
    "for key, value in list(fNewBassistsLinks.items()):\n",
    "    #print(key, value)\n",
    "    # Deleting Eddie Gomez doesn't work, but the overall result still functions... \n",
    "    # I should definitely come back and clean this code up\n",
    "    if (key == 'Ram John Holder') or (key == 'Bill Evans') or (key == 'Eddie Gomez' and eGomez == False):\n",
    "        if key == 'Eddie Gomez':\n",
    "            eGomez = True\n",
    "        del fNewBassistsLinks[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "uBassistsYears = dict()\n",
    "\n",
    "body = soup.find('div', {'class' : 'mw-parser-output'})\n",
    "first_h2 = body.find('h2')\n",
    "\n",
    "for sib in first_h2.next_siblings:\n",
    "    if type(sib) == bs4.element.Tag:\n",
    "        for li in sib.find_all('li'):\n",
    "            s = li.text\n",
    "            #print(s)\n",
    "            \n",
    "            noParens = False\n",
    "            yearDates = ''\n",
    "            fullName = ''\n",
    "            \n",
    "            # Extracting the dates from s\n",
    "            # Using regular expression to extract everything within the parentheses and assign it to variable years\n",
    "            if re.search('\\(([^)]+)', s):\n",
    "                years = re.search('\\(([^)]+)', s).group(1)\n",
    "            # Testing if the format of the dates is \"born XXXX\" or \"XXXX-XXXX\" by simply determining if there \n",
    "            # is a whitespace in the string (I should think about making this process a little more robust)\n",
    "                if len(years.split()) > 1:\n",
    "                # Don't want the word \"born\" in the year data, so only taking the year using .split()\n",
    "                    yearDates = years.split()[1].strip()\n",
    "                else:\n",
    "                    yearDates = years.strip()\n",
    "            else:\n",
    "                yearDates = 'NaN'\n",
    "            # If there is no year data given, then there are no parentheses, which allows the scripts to \n",
    "            # properly extract the artist's name\n",
    "                noParens = True\n",
    "            \n",
    "            # Extracting the artist's name from s\n",
    "            # If there are parentheses, simply take a substring of s that ends at the first '('\n",
    "            if noParens == False:\n",
    "                name = s[0:s.find('(')]\n",
    "                fullName = name.strip()\n",
    "            # If there aren't any parentheses, then just take s as it is (stripped of whitespace of course)\n",
    "            else:\n",
    "                fullName = s.strip()\n",
    "            \n",
    "            #print(fullName, yearDates, '\\n')\n",
    "        \n",
    "            # Now append the name and year data to the uPianistsYears dictionary\n",
    "            uBassistsYears.update( {fullName : yearDates})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBassistsYears = dict(list(uBassistsYears.items())[0:443])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is Chester Zardis being stored as a weird description in fNewBassistsLinks? But it still works so \n",
    "# ¯\\_(ツ)_/¯\n",
    "index = 0\n",
    "for key in list(newBassistsYears.keys()):\n",
    "    index += 1\n",
    "    #print(key, index)\n",
    "    if key == 'Chester Zardis, nickname: \"Bear\" or \"Little Bear\"':\n",
    "        newBassistsYears['Chester Zardis'] = newBassistsYears['Chester Zardis, nickname: \"Bear\" or \"Little Bear\"']\n",
    "        del newBassistsYears['Chester Zardis, nickname: \"Bear\" or \"Little Bear\"']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To combine the two dictionaries so that for each artist's name, there is a wiki and years listed\n",
    "# I'm not exactly sure how this works, maybe I should work on figuring that out\n",
    "combinedList = [fNewBassistsLinks, newBassistsYears]\n",
    "fullBassistsList = dict()\n",
    "\n",
    "for artist in fNewBassistsLinks.keys():\n",
    "    fullBassistsList[artist] = tuple(fullBassistsList[artist] for fullBassistsList in combinedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(fullBassistsList))\n",
    "\n",
    "#for key, value in fullBassistsList.items():\n",
    "    #print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom dictionary with pyspellchecker that contains most, if not all, instruments used to play jazz\n",
    "spell = SpellChecker(language = None, case_sensitive = True)\n",
    "a = spell.word_frequency.load_words(['Piano', 'Vocals', 'Keyboards', 'Double bass', 'Saxophone', 'Clarinet', 'Trumpet', \n",
    "                                    'Trombone', 'Drums', 'Guitar', 'Flute', 'Vibraphone', 'Banjo', 'Violin', 'Viola', \n",
    "                                    'Cello', 'Synthesizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahmed Abdul-Malik 1927–1993\n",
      "Placide Adams 1929–2003\n",
      "Samuel Adams 1985\n",
      "Osama Afifi NaN\n",
      "Moses Allen 1907–1983\n",
      "Vernon Alley 1915–2004\n",
      "Ben Allison 1966\n",
      "Bjørn Alterhaug 1945\n",
      "Hayes Alvis 1907–1972\n",
      "Andreas Amundsen 1980\n",
      "Erik Amundsen 1937–2015\n",
      "Arild Andersen 1945\n",
      "Thomas Winther Andersen 1969\n",
      "Reid Anderson 1970\n",
      "Bjørnar Andresen 1945–2004\n",
      "Roger Arntzen 1976\n",
      "Jim Aton 1925–2008\n",
      "Edvard Askeland 1954\n",
      "Tine Asmundsen 1963\n",
      "Harry Babasin 1921–1988\n",
      "Roy Babbington 1940\n",
      "Don Bagley 1927–2012\n",
      "Steve Bailey 1960\n",
      "Victor Bailey 1960–2016\n",
      "Fred Thelonious Baker 1960\n",
      "Tom Barney NaN\n",
      "Phil Bates 1931\n",
      "Carles Benavent 1954\n",
      "Joe Benjamin 1919–1974\n",
      "Max Bennett 1928-2018\n"
     ]
    }
   ],
   "source": [
    "# Creating DataFrame to store the information on the pianists\n",
    "pDF = pd.DataFrame(columns = ['artist', 'instrument', 'birthdate', 'deathdate', 'birth_year', 'death_year'])\n",
    "\n",
    "# Main script that will take the wikis in the fullPianistsList dictionary and scrape the data in the biographical\n",
    "# table for each artist. I have done much research into the legality and ethicality of this operation, and I've \n",
    "# determined that it's okay to run a script like this as long as I have at least a one-second delay inbetween \n",
    "# each iteration of the below for loop, so as to not create too much traffic. \n",
    "\n",
    "# pianist = pianist's name; linkYear = a tuple where the first element is the wiki link and the second element \n",
    "# is the string containing the artist's dates: ( /wiki/ARTIST_NAME, (XXXX OR XXXX-XXXX) )\n",
    "\n",
    "# For testing the DataFrame:\n",
    "runs = 0\n",
    "\n",
    "for bassist, linkYear in fullBassistsList.items():\n",
    "    \n",
    "    # For testing purposes\n",
    "    if runs < 30:\n",
    "        print(bassist, linkYear[1])\n",
    "    \n",
    "        bday = ''\n",
    "        dday = ''\n",
    "        \n",
    "        bYear = ''\n",
    "        dYear = ''\n",
    "        \n",
    "        # instrumentList is important for a later operation, although it can most likely be simplified\n",
    "        instrumentList = []\n",
    "    \n",
    "        # Create the link by appending the wikipedia link for the artist onto the end of the general wikipedia link\n",
    "        wikiLink = 'https://en.wikipedia.org' + linkYear[0]\n",
    "    \n",
    "        # Following the basic requests and bs4 process to read in a webpage\n",
    "        pInfo = requests.get(wikiLink)\n",
    "        pSoup = bs4.BeautifulSoup(pInfo.text, \"html.parser\")\n",
    "    \n",
    "        # Finding the biographical information table, which is always in a table with the class = infobox vcard plainlist\n",
    "        # However, some pages don't have the table, which is why there is a conditional first. \n",
    "        if pSoup.find('table', {'class' : 'infobox vcard plainlist'}):\n",
    "            \n",
    "    \n",
    "            # aTable is the tag in which the script will find all of the necessary information\n",
    "            aTable = pSoup.find('table', {'class' : 'infobox vcard plainlist'})\n",
    "    \n",
    "            # All of the necessary information is within the <tr> row element \n",
    "            for table in aTable.find_all('tr'):\n",
    "    \n",
    "                # First, finding the primary instrument of the artist (which is all that this project will\n",
    "                # be concerned with for the moment, sorry multi-instrumentalists). The instrument data is listed in\n",
    "                # the <td> tag with the class = note. However, because the script must account for the fact that\n",
    "                # there are multi-instrumentalists, the script only returns the first instrument that is found. \n",
    "                # In lieu of a more efficient way to do this, there is an index that will only allow the instrumentList\n",
    "                # to append the first instrument it finds. This should probably be fixed too. \n",
    "                if table.find('td', {'class' : 'note'}):\n",
    "                    index = 0\n",
    "                    for string in table.find('td', {'class' : 'note'}).stripped_strings:\n",
    "                        if index == 0:\n",
    "                            string = string.split(',')[0]\n",
    "                            string = spell.correction(string)\n",
    "                            instrumentList.append(string.split(',')[0])\n",
    "                            index += 1\n",
    "        \n",
    "                # Finding the birthday of the artist. If there is one, it is always contained within the span class = \n",
    "                # bday tag, and the date can be accessed with the .string bs4 method\n",
    "                # THERE ARE ISSUES HERE BECAUSE OF WIKIPEDIA SHODDY FORMATTING - FIGURE THIS OUT\n",
    "                if table.find('span', {'class' : 'bday'}):\n",
    "                    #print(table.find('span', {'class' : 'bday'}).string)\n",
    "                    bday = table.find('span', {'class' : 'bday'}).string\n",
    "                    bYear = bday[0:4]\n",
    "        \n",
    "                # Finding the deathdate of the artist. If there is one, it is usually contained within the span style = \n",
    "                # display:none tag. However, there are multiple pieces of information that can be contained within a \n",
    "                # style = diplay:none tag. Fortunately, the death date is the only piece of information that is \n",
    "                # accessible via the .string method, so the script checks for the possibility of the .string method\n",
    "                # and then removes the parentheses which always surround it. \n",
    "                if table.find('span', {'style' : 'display:none'}):\n",
    "                    for row in table.find_all('span', {'style' : 'display:none'}):\n",
    "                        if row.string:\n",
    "                            #print(row.string[1:-1])\n",
    "                            dday = row.string[1:-1]\n",
    "                            dYear = dday[0:4]\n",
    "                    \n",
    "     \n",
    "            # Lines 88-105 and lines 116-132 use the year data from the \"List of jazz pianists\" page to fill in \n",
    "            # the DataFrame when information is not found in the individual artist's vtable\n",
    "            if not bday:\n",
    "                bday = linkYear[1][0:4]\n",
    "                bYear = bday\n",
    "                \n",
    "            if not dday:\n",
    "                if linkYear[1] == 'NaN':\n",
    "                    dday = 'NaN'\n",
    "                    dYear = 'NaN'\n",
    "                else:\n",
    "                    if len(linkYear[1]) > 4:\n",
    "                        dday = linkYear[1][5:9]\n",
    "                        dYear = dday\n",
    "                    else:\n",
    "                        dday = 'NaN' # Make these 'Present' if other solution doesn't work\n",
    "                        dYear = 'NaN'\n",
    "            \n",
    "            if not instrumentList:\n",
    "                instrumentList.append('Upright bass')\n",
    "        \n",
    "            #print('\\n')\n",
    "        \n",
    "            # Time delay on for loop\n",
    "            sleep(1.0)\n",
    "            \n",
    "            \n",
    "    \n",
    "        else:\n",
    "            #print('\\n')\n",
    "            if len(linkYear[1]) > 4:\n",
    "                bday = linkYear[1][0:4]\n",
    "                bYear = bday\n",
    "                dday = linkYear[1][5:9]\n",
    "                dYear = dday\n",
    "            else:\n",
    "                bday = linkYear[1]\n",
    "                bYear = bday\n",
    "                if bday == 'NaN':\n",
    "                    dday = 'NaN'\n",
    "                    dYear = 'NaN'\n",
    "                else:\n",
    "                    dday = 'NaN'  # Make these 'Present' if other solution doesn't work\n",
    "                    dYear = 'NaN'\n",
    "                    \n",
    "            if not instrumentList:\n",
    "                instrumentList.append('Upright bass')\n",
    "                \n",
    "                \n",
    "        # Appending the values to the DataFrame        \n",
    "        pDF = pDF.append( {'artist' : bassist, 'instrument' : instrumentList[0], 'birthdate' : str(bday),\n",
    "                           'deathdate' : str(dday), 'birth_year' : bYear, 'death_year' : dYear}, ignore_index = True)\n",
    "    \n",
    "        runs += 1\n",
    "        #print(runs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# To make it easier to loop through DataFrame? \n",
    "# pDF.set_index('Artist', inplace = True)\n",
    "\n",
    "# Deleting Birth Year and Death Year columns for now because I don't think they're that necessary given the solution\n",
    "# I've decided to pursue. However, I will leave this like so for now because I don't want to commit to this solution \n",
    "# yet. \n",
    "pDF.drop(columns = ['birth_year', 'death_year'], inplace = True)\n",
    "\n",
    "#print(pDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'alive' column to the DataFrame using np.select() \n",
    "\n",
    "conditions = [ (pDF['birthdate'] == 'NaN') & (pDF['deathdate'] == 'NaN'), (pDF['deathdate'] == 'NaN'), \n",
    "             (pDF['deathdate'] != 'NaN') ]\n",
    "\n",
    "values = ['NaN', True, False]\n",
    "\n",
    "pDF['alive'] = np.select(conditions, values)\n",
    "#print(pDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forcing all of the dates into datetime objects \n",
    "\n",
    "pDF['bday_dt'] = pd.to_datetime(pDF['birthdate'], errors = 'coerce')\n",
    "pDF['dday_dt'] = pd.to_datetime(pDF['deathdate'], errors = 'coerce')\n",
    "\n",
    "# Account for the age of people who are alive today as well\n",
    "conditions = [ (pDF['alive'] == 'True'), (pDF['alive'] == 'False'), (pDF['alive'] == 'NaN') ]\n",
    "\n",
    "values = [ (pd.to_datetime('today') - pDF['bday_dt']).astype('timedelta64[Y]').astype(float),\n",
    "         (pDF['dday_dt'] - pDF['bday_dt']).astype('timedelta64[Y]').astype(float), 'NaN' ]\n",
    "\n",
    "pDF['age_yrs'] = np.select(conditions, values)\n",
    "\n",
    "#display(pDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs the .csv file that was then cleaned in Excel and put back into the jazz-pianist-files folder as \n",
    "# jazz_pianists_cleaned1.csv\n",
    "pDF.to_csv('jazz_bassists1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
